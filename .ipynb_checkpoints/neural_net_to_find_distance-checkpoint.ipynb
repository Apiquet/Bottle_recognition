{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import datetime \n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# number of epoch\n",
    "num_epochs = 1\n",
    "# batch size to compute mini-batch\n",
    "batch_size = 1\n",
    "# number of pixels in the image \n",
    "input_size = 2\n",
    "# number of possible digit: 0 to 9 \n",
    "num_class = 1\n",
    "# small step to find a minima\n",
    "learning_rate = 0.004\n",
    "# hidden size\n",
    "hidden_size = 500\n",
    "\n",
    "# Fully connected neural network\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU() \n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.layer3 = nn.Linear(hidden_size, num_class)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = self.layer1(x)\n",
    "        outputs = self.relu(outputs)\n",
    "        outputs = self.layer2(outputs)\n",
    "        outputs = self.relu(outputs)\n",
    "        outputs = self.layer3(outputs)\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train each model\n",
    "def train_model(model_, my_train_input_, my_train_target_, criterion_, optimizer_,num_epochs_,batch_size_):\n",
    "    # getting start time of train to get the train time at the end thanks to \"end_time\"\n",
    "    start_time = datetime.datetime.now()\n",
    "    # list to get train errors at each epoch\n",
    "    train_error = []\n",
    "    # train function\n",
    "    for epoch in range(1, num_epochs_+1):\n",
    "        # using technique of mini batch (size of the batch in the function's parameters)\n",
    "        for i in range(int(len(my_train_input_)/batch_size_)):  \n",
    "            # getting images and labels in right format\n",
    "            x = my_train_input_.narrow(0,i*batch_size_,batch_size_).to(device)\n",
    "            labels = my_train_target_.narrow(0,i*batch_size_,batch_size_).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model_(x)\n",
    "            loss = criterion_(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer_.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_.step()\n",
    "            # getting train error at each epoch\n",
    "            train_error.append(test_accuracy(model_, my_train_input_, my_train_target_))\n",
    "        # getting end time and training time\n",
    "        end_time = datetime.datetime.now()\n",
    "        training_time = end_time - start_time\n",
    "        print ('Loss: {:.4f} on epoch: {}, train error: {:.5f}'.format(loss.item(),epoch,train_error[-1]))\n",
    "    return train_error, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model_, my_test_input_, my_test_target_):\n",
    "    total = my_test_input_.size(0)\n",
    "    outputs = model_(my_test_input_)\n",
    "    print(outputs)\n",
    "    print(my_test_target_)\n",
    "    well_predicted_count = (outputs == my_test_target_).sum().item()\n",
    "\n",
    "    return 1 - well_predicted_count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[469.0000,   3.2100],\n",
      "        [294.0000,   3.2700],\n",
      "        [202.0000,   3.2000],\n",
      "        [154.0000,   3.2800],\n",
      "        [119.0000,   3.4000],\n",
      "        [ 97.0000,   3.2300],\n",
      "        [ 76.0000,   3.3000],\n",
      "        [ 66.0000,   3.0000],\n",
      "        [ 59.0000,   2.9500],\n",
      "        [ 51.0000,   3.0000]], dtype=torch.float64)\n",
      "tensor([[ 30],\n",
      "        [ 50],\n",
      "        [ 70],\n",
      "        [100],\n",
      "        [130],\n",
      "        [160],\n",
      "        [200],\n",
      "        [230],\n",
      "        [260],\n",
      "        [300]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "data_x = numpy.matrix([[469,3.21],[294,3.27],[202,3.2],[154,3.28],[119,3.4],[97,3.23],[76, 3.3],[66,3],[59,2.95],[51,3]])\n",
    "data_y = numpy.matrix([[30],[50],[70],[100],[130],[160],[200],[230],[260],[300]])\n",
    "input_ = torch.from_numpy(data_x)\n",
    "target_ = torch.from_numpy(data_y)\n",
    "\n",
    "print(input_)\n",
    "print(target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4000.0120],\n",
      "        [2508.3938],\n",
      "        [1724.1837],\n",
      "        [1315.1006],\n",
      "        [1016.8470],\n",
      "        [ 829.2392],\n",
      "        [ 650.3024],\n",
      "        [ 564.8984],\n",
      "        [ 505.2095],\n",
      "        [ 437.0632]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 30.],\n",
      "        [ 50.],\n",
      "        [ 70.],\n",
      "        [100.],\n",
      "        [130.],\n",
      "        [160.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [260.],\n",
      "        [300.]])\n",
      "tensor([[-126.5109],\n",
      "        [ -79.3566],\n",
      "        [ -54.5590],\n",
      "        [ -41.6264],\n",
      "        [ -32.2001],\n",
      "        [ -26.2603],\n",
      "        [ -20.6022],\n",
      "        [ -17.8876],\n",
      "        [ -15.9972],\n",
      "        [ -13.8398]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 30.],\n",
      "        [ 50.],\n",
      "        [ 70.],\n",
      "        [100.],\n",
      "        [130.],\n",
      "        [160.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [260.],\n",
      "        [300.]])\n",
      "tensor([[3.0825],\n",
      "        [1.9694],\n",
      "        [1.3827],\n",
      "        [1.0792],\n",
      "        [0.8591],\n",
      "        [0.7159],\n",
      "        [0.5874],\n",
      "        [0.5187],\n",
      "        [0.4770],\n",
      "        [0.4336]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 30.],\n",
      "        [ 50.],\n",
      "        [ 70.],\n",
      "        [100.],\n",
      "        [130.],\n",
      "        [160.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [260.],\n",
      "        [300.]])\n",
      "tensor([[14.0002],\n",
      "        [ 8.8277],\n",
      "        [ 6.1058],\n",
      "        [ 4.6898],\n",
      "        [ 3.6592],\n",
      "        [ 3.0039],\n",
      "        [ 2.3893],\n",
      "        [ 2.0853],\n",
      "        [ 1.8809],\n",
      "        [ 1.6525]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 30.],\n",
      "        [ 50.],\n",
      "        [ 70.],\n",
      "        [100.],\n",
      "        [130.],\n",
      "        [160.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [260.],\n",
      "        [300.]])\n",
      "tensor([[42.8887],\n",
      "        [26.9719],\n",
      "        [18.5992],\n",
      "        [14.2385],\n",
      "        [11.0624],\n",
      "        [ 9.0518],\n",
      "        [ 7.1504],\n",
      "        [ 6.2244],\n",
      "        [ 5.5893],\n",
      "        [ 4.8714]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 30.],\n",
      "        [ 50.],\n",
      "        [ 70.],\n",
      "        [100.],\n",
      "        [130.],\n",
      "        [160.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [260.],\n",
      "        [300.]])\n",
      "tensor([[111.2949],\n",
      "        [ 69.9127],\n",
      "        [ 48.1485],\n",
      "        [ 36.8067],\n",
      "        [ 28.5431],\n",
      "        [ 23.3233],\n",
      "        [ 18.3702],\n",
      "        [ 15.9754],\n",
      "        [ 14.3200],\n",
      "        [ 12.4404]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 30.],\n",
      "        [ 50.],\n",
      "        [ 70.],\n",
      "        [100.],\n",
      "        [130.],\n",
      "        [160.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [260.],\n",
      "        [300.]])\n",
      "tensor([[246.3783],\n",
      "        [154.6997],\n",
      "        [106.4861],\n",
      "        [ 81.3548],\n",
      "        [ 63.0414],\n",
      "        [ 51.4845],\n",
      "        [ 40.5001],\n",
      "        [ 35.2056],\n",
      "        [ 31.5322],\n",
      "        [ 27.3535]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 30.],\n",
      "        [ 50.],\n",
      "        [ 70.],\n",
      "        [100.],\n",
      "        [130.],\n",
      "        [160.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [260.],\n",
      "        [300.]])\n",
      "tensor([[494.9975],\n",
      "        [310.7028],\n",
      "        [213.7889],\n",
      "        [163.2627],\n",
      "        [126.4393],\n",
      "        [103.2209],\n",
      "        [ 81.1319],\n",
      "        [ 70.5106],\n",
      "        [ 63.1273],\n",
      "        [ 54.7199]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 30.],\n",
      "        [ 50.],\n",
      "        [ 70.],\n",
      "        [100.],\n",
      "        [130.],\n",
      "        [160.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [260.],\n",
      "        [300.]])\n",
      "tensor([[933.8673],\n",
      "        [586.0673],\n",
      "        [403.1786],\n",
      "        [307.8189],\n",
      "        [238.3171],\n",
      "        [194.5137],\n",
      "        [152.8181],\n",
      "        [132.7974],\n",
      "        [118.8647],\n",
      "        [102.9879]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 30.],\n",
      "        [ 50.],\n",
      "        [ 70.],\n",
      "        [100.],\n",
      "        [130.],\n",
      "        [160.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [260.],\n",
      "        [300.]])\n",
      "tensor([[1637.1256],\n",
      "        [1027.2882],\n",
      "        [ 706.6165],\n",
      "        [ 539.4051],\n",
      "        [ 417.5291],\n",
      "        [ 340.7379],\n",
      "        [ 267.6174],\n",
      "        [ 232.5399],\n",
      "        [ 208.1127],\n",
      "        [ 180.2709]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 30.],\n",
      "        [ 50.],\n",
      "        [ 70.],\n",
      "        [100.],\n",
      "        [130.],\n",
      "        [160.],\n",
      "        [200.],\n",
      "        [230.],\n",
      "        [260.],\n",
      "        [300.]])\n",
      "Loss: 197.0121 on epoch: 1, train error: 1.00000\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_class).to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)  \n",
    "train_error, training_time = train_model(model, input_.float(), target_.float(), criterion, optimizer,num_epochs,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14.7696, 12.9990, 13.5972, 14.1123, 17.0108, 22.6005, 13.5195, 16.7820,\n",
       "        13.8601, 17.7458, 15.8322, 13.6685, 13.9426, 20.3678, 15.1451, 12.9439,\n",
       "        14.3262, 20.6364, 15.6986, 14.9710, 15.8282, 13.2200, 15.4951, 18.4752,\n",
       "        15.1390, 15.0656, 14.9025, 14.2051, 15.9589, 18.3631, 13.9445, 15.4239,\n",
       "        13.7188, 15.5536, 14.3146, 15.3523, 16.3967, 22.0201, 15.6569, 12.4195,\n",
       "        14.2364, 14.1782, 14.7375, 12.3826, 13.4828, 12.4341, 17.5544, 14.2052,\n",
       "        14.6860, 13.8939, 20.0757, 15.0123, 15.1471, 15.8959, 13.5900, 16.2137,\n",
       "        13.0337, 14.8032, 13.8524, 14.4916, 14.4134, 14.8064, 12.4903, 13.8422,\n",
       "        14.3710, 15.3202, 13.7717, 13.1972, 12.6730, 14.2258, 15.0868, 14.8226,\n",
       "        21.6567, 14.0519, 15.8046, 18.9750, 13.0635, 14.6599, 18.0238, 17.3375,\n",
       "        14.8592, 14.7172, 13.3466, 18.3617, 14.0268, 13.5351, 13.3650, 14.2281,\n",
       "        14.1835, 15.4894, 14.1583, 15.0794, 12.6972, 13.7437, 15.8107, 13.5619,\n",
       "        26.0594, 16.4941, 17.7803, 13.0250, 12.8893, 12.2795, 18.0692, 16.4474,\n",
       "        13.9885, 14.7055, 13.5375, 17.5270, 13.3736, 18.5164, 15.3647, 20.1858,\n",
       "        15.2635, 12.8264, 14.8497, 12.9538, 19.1553, 16.4149, 13.7767, 13.4875,\n",
       "        14.2619, 13.6375, 14.9328, 14.9357, 14.1213, 18.9670, 13.3981, 14.7696,\n",
       "        12.6161, 17.8309, 14.3916, 14.8919, 20.3260, 14.1455, 14.7935, 12.2878,\n",
       "        12.7450, 20.4200, 18.3624, 14.4194, 13.3803, 14.3402, 14.2562, 15.6443,\n",
       "        14.9945, 23.9212, 13.2142, 15.1883, 13.5046, 12.9775, 15.8922, 13.4271,\n",
       "        13.3620, 13.9186, 14.8010, 14.7764, 14.3338, 18.5694, 14.6645, 13.0976,\n",
       "        18.3893, 14.0426, 13.7961, 13.9304, 13.4991, 13.3697, 13.9372, 14.4955,\n",
       "        14.4494, 13.1848, 13.6136, 13.5705, 15.4439, 16.1461, 12.7934, 19.4349,\n",
       "        14.6485, 21.3914, 16.5628, 14.7432, 13.7267, 17.2460, 13.0956, 12.3318,\n",
       "        13.4036, 14.1493, 21.9884, 16.9526, 13.0046, 13.9369, 14.0563, 13.8520,\n",
       "        16.1014, 16.0671, 13.8055, 14.0227, 13.2793, 21.1130, 14.1387, 14.3697,\n",
       "        14.3625, 16.0942, 13.9493, 15.9067, 16.7193, 16.3837, 21.8096, 14.9016,\n",
       "        16.1018, 17.2176, 12.9001, 19.9532, 21.0336, 14.2127, 12.2895, 15.1041,\n",
       "        13.2217, 13.8410, 14.2626, 17.3975, 18.2100, 16.7588, 21.3473, 16.0561,\n",
       "        17.0510, 17.3312, 14.7185, 14.1450, 13.5647, 13.3105, 16.7024, 15.6959,\n",
       "        17.0381, 14.0765, 14.1502, 17.2890, 13.8783, 17.9325, 18.5487, 12.8778,\n",
       "        13.3211, 17.0268, 14.3965, 14.3820, 13.6219, 17.7494, 13.8995, 13.3100,\n",
       "        23.5332, 13.8560, 14.6339, 19.6287, 13.3064, 14.6112, 13.0346, 17.8668,\n",
       "        14.9060, 14.0342, 14.6196, 18.1600, 18.2745, 17.5008, 25.7399, 14.1766,\n",
       "        14.6302, 14.3598, 15.3365, 19.7383, 14.8080, 14.3913, 12.7549, 14.9195,\n",
       "        19.2066, 13.5594, 14.3164, 20.5327, 21.8824, 19.0305, 14.4303, 18.6097,\n",
       "        14.4569, 13.1741, 17.3846, 14.6063, 14.1456, 15.4258, 16.8591, 14.1189,\n",
       "        18.6347, 20.8007, 16.5464, 14.2601, 13.9620, 12.5720, 13.6551, 14.5034,\n",
       "        16.0899, 13.4852, 13.4441, 12.7004, 14.2322, 14.1168, 15.5375, 12.3213,\n",
       "        14.5568, 13.2324, 14.7062, 13.6617, 14.3640, 14.8172, 13.5761, 16.5149,\n",
       "        18.1195, 14.2225, 13.7607, 17.7330, 15.3714, 18.4161, 12.7976, 13.3936,\n",
       "        13.1618, 15.7339, 12.3768, 18.7992, 14.4107, 14.6084, 14.8616, 14.8148,\n",
       "        12.8545, 14.8034, 15.4676, 14.5752, 13.7203, 16.6176, 14.0387, 17.7280,\n",
       "        21.3817, 26.4838, 12.7062, 13.6604, 16.5469, 13.4329, 14.5795, 14.5917,\n",
       "        15.2260, 14.2425, 13.2557, 14.0740, 18.5809, 15.7570, 17.0601, 14.6333,\n",
       "        17.4896, 15.1891, 15.5808, 13.0044, 14.1783, 18.0719, 15.0431, 22.2030,\n",
       "        13.7560, 13.4257, 14.7978, 23.3789, 15.1825, 12.7725, 13.3292, 15.2022,\n",
       "        14.0564, 20.5109, 14.2747, 22.3258, 15.9137, 13.5550, 14.4631, 12.7793,\n",
       "        19.6968, 14.2209, 13.8971, 15.3851, 16.1072, 14.2318, 12.8606, 13.5444,\n",
       "        16.2983, 13.8839, 13.8124, 14.5883, 15.9690, 13.2685, 15.5812, 12.8781,\n",
       "        17.2448, 14.3657, 22.5837, 23.4299, 14.3400, 14.6401, 18.3867, 12.7277,\n",
       "        13.0901, 13.6195, 14.4970, 16.8511, 14.1492, 17.4220, 14.3193, 15.1246,\n",
       "        14.2481, 13.3635, 21.0162, 14.4603, 15.0724, 14.3007, 15.8710, 13.2239,\n",
       "        12.9094, 13.7830, 13.9831, 15.0378, 14.7532, 14.0975, 13.0257, 13.6948,\n",
       "        14.3273, 13.8676, 14.3891, 14.7999, 13.0390, 16.6210, 13.3344, 13.7244,\n",
       "        15.3122, 13.6602, 14.6109, 14.7266, 17.4776, 13.5891, 14.6781, 16.1221,\n",
       "        23.3465, 13.5421, 13.5763, 16.4608, 16.1580, 12.8115, 14.1935, 14.0175,\n",
       "        13.9865, 19.2689, 12.9939, 13.3725, 17.6240, 14.8803, 15.7490, 12.9906,\n",
       "        14.0045, 14.9398, 15.0372, 12.3002, 14.4487, 14.9813, 16.2803, 15.2316,\n",
       "        14.6915, 14.2840, 13.7659, 15.4945, 14.4661, 13.2900, 14.8920, 15.9627,\n",
       "        14.5486, 12.2665, 14.8641, 12.5062, 18.2526, 15.1981, 16.9520, 19.1975,\n",
       "        17.2006, 15.0907, 13.8133, 14.1632, 18.7877, 13.1517, 19.5869, 14.8278,\n",
       "        13.5450, 18.9052, 12.8092, 14.4715, 13.3507, 13.5327, 18.2866, 12.5665,\n",
       "        14.0268, 12.9398, 13.8313, 13.3863], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(Tensor([51,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
